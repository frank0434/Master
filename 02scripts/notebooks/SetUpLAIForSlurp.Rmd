---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.5.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

<!-- #region -->
# Background Information 

The slurp model requirs three essential inputs:  
1. Met.   
2. Canopy cover. 
3. Initial soil conditions. 


Model set up   
1. No notion of population or rowSpacing. but need to be provided via   
```Slurp.Sow(cultivar: StaticCrop, population: 1, depth: 10, rowSpacing: 150);```

2. Altering Slurp properties during runs  
In some cases users will wish to change properties of Slurp while the simulation is running. This can be done using a the set method in a manager script.   
```
object LAIResetValue = leaflai;
zone.Set("Slurp.Leaf.LAIFunction.Value()", LAIResetValue);
object HeightResetValue = CoverToday * MaximumHeight;
zone.Set("Slurp.Leaf.HeightFunction.Value()", HeightResetValue);
```
Model is driven by thermal time, so temperature and base temperature are critical?

A broken-stick threshold model was used in the thesis 

Tt is accumulated linearly at a rate of 0.7 °Cd/°C up to 15 °C and then at a rate of 1.0 until 30 

$T_b$ = 1
$T_t$ = 0.7 °Cd/°C when temperature below 15 
$T_t$ = 1 °Cd/°C when temperature is in 15 and 30 




<!-- #endregion -->

# Prepare the cover data 

Light interception was not measured directly due to the instrement reported incorrect measurements for crops grown under droughts.

Frational light interception can be calculated from desctructive LAI   

$$R/R_0 = 1 - exp(-k\times LAI)$$

where (extinction coefficient) k was obtained by sunscan measurements. more details in the thesis and 2017 paper of Richard's

k values differ seasonally. 
k for all Iversen 12 and spring(Sep - Nov) and autumn(Feb - Apr) on both stone soils - **0.94 $\pm$ 0.014**  
k for summer (Dec - Jan) on both stone soils - **0.66 $\pm$ 0.013**

```{python}
#load packages
import sqlite3
import re
import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
```

```{python}
def print_full(x):
    pd.set_option('display.max_rows', len(x))
    print(x)
    pd.reset_option('display.max_rows')
```

```{python}
# Build connection with db
con = sqlite3.connect('../../03processed-data/Richard.sqlite3')
mycur = con.cursor() 
mycur.execute("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;")
(mycur.fetchall())
```

```{python}
# Read data in 
biomass = pd.read_sql('Select * from biomass',  con)
met_AD = pd.read_sql('Select * from met_AshleyDene', con)
met_I12 = pd.read_sql('Select * from met_Iversen12', con)
```

```{python}
LAI_Height = biomass.loc[(biomass['Seed'] == 'CS')
                         & (biomass['Harvest.No.']!='Post'), 
                         ['Experiment', 'Clock.Today', 'SowingDate', 'Rep',
                          'Plot', 'Rotation.No.', 'Harvest.No.', 'Height','LAImod']]
```

```{python}
# Plot that had 'Post' measurement should be out 
LAI_Height[(LAI_Height['Harvest.No.'] == 'Post') & (LAI_Height.LAImod==0)]
```

```{python}
# Add the k for all 
LAI_Height['k'] = 0.94
# Replace the k for the summur crop in Ashley Dene
# LAI_Height.loc[(LAI_Height['Clock.Today'] > '2011-11-30') 
#                & (LAI_Height['Clock.Today'] < '2012-03-01') 
#                & (LAI_Height['Experiment'] == 'AshleyDene'), 'k'] = 0.66
```

```{python}
LAI_Height['Date'] = pd.to_datetime(LAI_Height['Clock.Today']).dt.strftime('%Y %b')
```

```{python}
LAI = LAI_Height.pivot_table(index = 'Clock.Today', 
                    columns=['Experiment', 'SowingDate'],
                    values = 'LAImod')
# Change the index to datetime tyep
LAI.index = pd.to_datetime(LAI.index)
# Rename the index name 
LAI.index.name = 'Clock.Today'
# Normalise the datetime to midnight 
LAI.index = LAI.index.normalize()
LAI
```

# Met data to calculate thermal time 

```{python}
met_AD = met_AD.loc[:, ['year','day', 'maxt', 'mint','mean']]
met_AD['Experiment'] = 'AshleyDene'
met_I12 = met_I12.loc[(met_I12['year'] >= 2010)                       
                      & (met_I12['year'] < 2013), ['year','day', 'maxt', 'mint','mean']]
met_I12['Experiment'] = 'Iversen12'
met = pd.concat([met_AD, met_I12], ignore_index=True)
```

```{python}
# Change 4 digits year to the first date of the year
met['year'] = [str(year) + '-01-01' for year in met['year']]
met['year'] = pd.to_datetime(met['year'])
# Change the day to a delta days and add back to the year 
met['Clock.Today'] = met['year'] + pd.to_timedelta(met['day'], unit='D')
```

```{python}
met = met[(met['Clock.Today'] > '2010-06-01')
          &(met['Clock.Today'] < '2012-08-01')]

```

```{python}
# Verify the filter 
# Check if any weired values. 
grid = sns.FacetGrid(met, row ='Experiment',
                     aspect=2, sharex=False)
grid.map(plt.scatter, 'Clock.Today', 'mean')
grid.set_xticklabels(rotation=45)
grid.fig.tight_layout()
```

```{python}
# indexing 
met.set_index('Clock.Today', inplace = True)
```

```{python}
# Try 2 sites the same time 
ThermalTimeAccum = met.loc[:, 'mean'].cumsum()
ThermalTimeAccum.index = pd.to_datetime(ThermalTimeAccum.index)
```

## Combine thermal time with cover data


## Interpolate daily values 

**Note**  
The for loop below complains _ValueError: fp and xp are not of the same length._  

This is probably because the LI is in a wide form 
But the thermal data is in a long form which includs two sites 



## Process sites individually   

Ashley Dene first

```{python}
LAIAD = LAI.filter(regex = 'Ashley')
#Reindex coverdata frame to daily values
TTAccumAD = met.loc[met['Experiment'] == 'AshleyDene', 'mean'].cumsum()
TTAccumAD.index = pd.to_datetime(TTAccumAD.index)

LAIDailyAD = LAIAD.reindex(TTAccumAD.index)
LAIDailyAD.loc[:, 'AccumTT'] = TTAccumAD

```

```{python}
LAIDailyAD 
```

```{python}
LAIGroupedMeanAD = LAIDailyAD.groupby(axis=1, level=['Experiment', 'SowingDate']).mean()
```

```{python}
# Graph to check the data 
LAIGroupedMeanAD.loc[:,
                  [X for X in LAIGroupedMeanAD.columns if X != (   'AccumTT',     '')]].plot(figsize=(10, 6),style='o-')
```

#### Notes

MAYBE the starting point need to be forced to be 0

## Iversen12 LI interpolate

```{python}
LAII12 = LAI.filter(regex = 'Ive')

TTAccumI12 = met.loc[met['Experiment'] == 'Iversen12', 'mean'].cumsum()
TTAccumI12.index = pd.to_datetime(TTAccumI12.index)
LAIDailyI12 = LAII12.reindex(TTAccumI12.index)  #Reindex coverdata frame to daily values
LAIDailyI12.loc[:,'AccumTT'] = TTAccumI12
# Disabled as well 
for p in LAIDailyI12.columns:
    Obs = LAIDailyI12.loc[:,p].dropna()
    LAIDailyI12.loc[:,p] = np.interp(LAIDailyI12.AccumTT,
                                   LAIDailyI12.loc[Obs.index,'AccumTT'],Obs)
LAIGroupedMeanI12 = LAIDailyI12.groupby(axis=1, level=['Experiment', 'SowingDate']).mean()
```

# Force the starting point to be 0

```{python}
sowingdates = pd.read_sql('Select * from SowingDates',  con)
```

```{python}
sowingdates.AD = pd.to_datetime(sowingdates.AD)
sowingdates.I12 = pd.to_datetime(sowingdates.I12)

```

```{python}
# set index and rename columns 
sowingdates.set_index('SD', inplace=True)
sowingdates.columns = ['AshleyDene', 'Iversen12']
```

```{python}
LAIAD = LAI.filter(regex = 'Ashley')
#Reindex coverdata frame to daily values
TTAccumAD = met.loc[(met['Experiment'] == 'AshleyDene')
                    & (met.index > '2010-10-01'), 'mean'].cumsum()
TTAccumAD.index = pd.to_datetime(TTAccumAD.index)

LAIDailyAD = LAIAD.reindex(TTAccumAD.index)
LAIDailyAD.loc[:, 'AccumTT'] = TTAccumAD
```

```{python}
idx = pd.IndexSlice
LAIDailyAD.loc[LAIDailyAD.index == '2012-06-02', idx[:,'SD1']]
```

```{python}
# Force LAI to be zero
for sd in sowingdates.index:
    # Select the date for correpond sowing date
    date0 = sowingdates.at[sd, 'AshleyDene']
    # A slicer
    idx = pd.IndexSlice
    # Replace the row values with 0s
    LAIDailyAD.loc[LAIDailyAD.index <= date0, idx[:,sd]] = float(0.001)
    # Verification 
    df = LAIDailyAD.loc[LAIDailyAD.index == date0, idx[:,sd]]
#     print('\r')
#     print(date0)     
#     print(df)
```

#### Note   
There are still more than 4 plots for each sowing dates   
Due to seed line and harvest.no.  
The harvest.no **post** did not contribute to LAI. so should taken out.   
The Thermaltime df has duplicated the index.

```{python}
for p in LAIDailyAD.columns:
    Obs = LAIDailyAD.loc[:,p].dropna()
    LAIDailyAD.loc[:,p] = np.interp(LAIDailyAD.AccumTT,
                                   LAIDailyAD.loc[Obs.index,'AccumTT'],Obs)
```

```{python}
LAIGroupedMeanADForced = LAIDailyAD.groupby(axis=1, level=['Experiment', 'SowingDate']).mean()
# Graph to check the data 
LAIGroupedMeanADForced.loc[:,
                          [X for X in LAIGroupedMeanADForced.columns if X != (   'AccumTT',     '')]].\
plot(figsize=(10, 6),style='o-')

plt.savefig('../../05figures/StartJune_AD.png', dpi = 300, bbox_inches = 'tight')
```

#### Repeat for I12


```{python}
LAII12 = LAI.filter(regex = 'Ive')

TTAccumI12 = met.loc[(met['Experiment'] == 'Iversen12')
                      & (met.index > '2010-10-01'), 'mean'].cumsum()
TTAccumI12.index = pd.to_datetime(TTAccumI12.index)
LAIDailyI12 = LAII12.reindex(TTAccumI12.index)  #Reindex coverdata frame to daily values
LAIDailyI12.loc[:,'AccumTT'] = TTAccumI12

```

```{python}
for sd in sowingdates.index:
    # Select the date for correpond sowing date
    date0 = sowingdates.at[sd, 'Iversen12']
    # A slicer
    idx = pd.IndexSlice
    # Replace the row values with 0s
    LAIDailyI12.loc[LAIDailyI12.index <= date0, idx[:,sd]] = float(0.001)
    # Verification 
    df = LAIDailyI12.loc[LAIDailyI12.index == date0, idx[:,sd]]
#     print('\r')
#     print(date0)     
#     print(df)
```

```{python}
# Interpolate LAI daily value by thermal time 
for p in LAIDailyI12.columns:
    Obs = LAIDailyI12.loc[:,p].dropna()
    LAIDailyI12.loc[:,p] = np.interp(LAIDailyI12.AccumTT,
                                   LAIDailyI12.loc[Obs.index,'AccumTT'],Obs)

```

```{python}
LAIGroupedMeanI12Forced = LAIDailyI12.groupby(axis=1, level=['Experiment', 'SowingDate']).mean()
```

```{python}
# Graph to check the data 
LAIGroupedMeanI12Forced.loc[:,
                           [X for X in LAIGroupedMeanI12Forced.columns \
                            if X != (   'AccumTT',     '')]].plot(figsize=(10, 6),style='o-')
```

```{python}
LAIGroupedMeanI12Forced
```

```{python}
LAIGroupedMeanADForced
```

# Output the LI DAILY

```{python}
# Reset the index back to a column
LAIGroupedMeanADForced.columns
```

```{python}
CoverDFAD = LAIGroupedMeanADForced.drop('AccumTT', axis=1, level=0).stack([0,1]).reset_index()
```

```{python}
CoverDFAD.columns = ['Clock.Today', 'Experiment', 'SowingDate', 'LAImod']
```

```{python}
CoverDFAD[CoverDFAD['LAImod'] == 0]
```

```{python}
# Test
CoverDFAD.loc[CoverDFAD.SowingDate == 'SD1', ['Clock.Today', 'LAImod']].\
to_csv('../../03processed-data/CoverData/CoverDataSD1.csv',index = False)
```

```{python}
SDs = ['SD' + str(SD) for SD in range(1, 11)]
SDs
for i in SDs:
    CoverDFAD.loc[CoverDFAD.SowingDate == i,
                  ['Clock.Today', 'LAImod']].\
    to_csv('../../03processed-data/CoverData/LAIAshleyDene' + i + '.csv',index = False)
```

```{python}
CoverDFI12 = LAIGroupedMeanI12Forced.drop('AccumTT', axis=1, level=0).stack([0,1]).reset_index()
```

```{python}
CoverDFI12.columns = ['Clock.Today', 'Experiment', 'SowingDate', 'LAImod']
SDs = ['SD' + str(SD) for SD in range(1, 11)]
SDs
for i in SDs:
    CoverDFI12.loc[CoverDFI12['SowingDate'] == i, 
                   ['Clock.Today', 'LAImod']].\
    to_csv('../../03processed-data/CoverData/LAIIversen12' + i + '.csv',
                                                 index = False)
```

# Out put k value with light interception for Ashley Dene

```{python}
CoverDFAD['k'] = 0.94
CoverDFAD['LI'] = 1 - np.exp( - CoverDFAD['k'] * CoverDFAD['LAImod'])
CoverDFI12['k'] = 0.94
CoverDFI12['LI'] = 1 - np.exp( - CoverDFI12['k'] * CoverDFI12['LAImod'])
```

```{python}
SDs = ['SD' + str(SD) for SD in range(1, 11)]
SDs
for j in SDs:
    CoverDFAD.loc[(CoverDFAD['SowingDate'] == j),
                  ['Clock.Today', 'LI']]. \
    to_csv('../../03processed-data/CoverData/CoverAshleyDene' + j + '.csv',index = False)
```

```{python}
SDs = ['SD' + str(SD) for SD in range(1, 11)]
SDs
for j in SDs:
    CoverDFI12.loc[(CoverDFI12['SowingDate'] == j),
                  ['Clock.Today', 'LI']]. \
    to_csv('../../03processed-data/CoverData/CoverIversen12' + j + '.csv',index = False)
```

```{python}
LAI_Height.loc[LAI_Height['Experiment'] == 'AshleyDene', 'Height'].max()
LAI_Height.loc[LAI_Height['Experiment'] != 'AshleyDene', 'Height'].max()
```

#### Max height was _390 mm_ when the crop had full cover in AD
#### Max height was _595 mm_ when the crop had full cover in I12

```{python}
LAI_Height.loc[(LAI_Height['Experiment'] == 'AshleyDene')
               &(LAI_Height['Height'] > 38), :]
LAI_Height.loc[(LAI_Height['Experiment'] != 'AshleyDene')
               &(LAI_Height['Height'] > 58), :]
```

```{python}
df = LAI_Height.groupby(['Experiment','SowingDate', 'Clock.Today'])['LAImod'].mean()
df = df.reset_index()
sites = ['AshleyDene', 'Iversen12']
for i in sites:
    for j in SDs:
        df.loc[(df['Experiment'] == i) 
               & (df['SowingDate'] == j),
               ['Clock.Today', 'LAImod']]. \
        to_csv('../../03processed-data/CoverData/Observation' + i + j + '.csv',index = False)
```

```{python}
df

```
