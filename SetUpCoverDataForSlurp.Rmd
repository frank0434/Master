---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

<!-- #region -->
# Background Information 

The slurp model requirs three essential inputs:  
1. Met.   
2. Canopy cover. 
3. Initial soil conditions. 


Model set up   
1. No notion of population or rowSpacing. but need to be provided via   
```Slurp.Sow(cultivar: StaticCrop, population: 1, depth: 10, rowSpacing: 150);```

2. Altering Slurp properties during runs  
In some cases users will wish to change properties of Slurp while the simulation is running. This can be done using a the set method in a manager script.   
```
object LAIResetValue = leaflai;
zone.Set("Slurp.Leaf.LAIFunction.Value()", LAIResetValue);
object HeightResetValue = CoverToday * MaximumHeight;
zone.Set("Slurp.Leaf.HeightFunction.Value()", HeightResetValue);
```
Model is driven by thermal time, so temperature and base temperature are critical?

A broken-stick threshold model was used in the thesis 

Tt is accumulated linearly at a rate of 0.7 °Cd/°C up to 15 °C and then at a rate of 1.0 until 30 

$T_b$ = 1
$T_t$ = 0.7 °Cd/°C when temperature below 15 
$T_t$ = 1 °Cd/°C when temperature is in 15 and 30 




<!-- #endregion -->

# Prepare the cover data 

Light interception was not measured directly due to the instrement reported incorrect measurements for crops grown under droughts.

Frational light interception can be calculated from desctructive LAI   

$$R/R_0 = 1 - exp(-k\times LAI)$$

where (extinction coefficient) k was obtained by sunscan measurements. more details in the thesis and 2017 paper of Richard's

k values differ seasonally. 
k for all Iversen 12 and spring(Sep - Nov) and autumn(Feb - Apr) on both stone soils - **0.94 $\pm$ 0.014**  
k for summer (Dec - Jan) on both stone soils - **0.66 $\pm$ 0.013**

```{python}
#load packages
import sqlite3
import re
import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
```

```{python}
# Build connection with db
con = sqlite3.connect('./03processed-data/Richard.sqlite3')
mycur = con.cursor() 
mycur.execute("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;")
(mycur.fetchall())
```

```{python}
# Read data in 
biomass = pd.read_sql('Select * from biomass',  con)
met_AD = pd.read_sql('Select * from met_AshleyDene', con)
met_I12 = pd.read_sql('Select * from met_Iversen12', con)
```

```{python}
LAI_Height = biomass.loc[(biomass['Seed'] == 'CS')
                         & (biomass['Harvest.No.']!='Post'), 
                         ['Experiment', 'Clock.Today', 'SowingDate', 'Rep',
                          'Plot', 'Rotation.No.', 'Harvest.No.', 'Height','LAImod']]
```

```{python}
# Plot that had 'Post' measurement should be out 
LAI_Height[LAI_Height['Harvest.No.'] == 'Post']
```

```{python}
# Add the k for all 
LAI_Height['k'] = 0.94
# Replace the k for the summur crop in Ashley Dene
LAI_Height.loc[(LAI_Height['Clock.Today'] > '2011-11-30') 
               & (LAI_Height['Clock.Today'] < '2012-03-01') 
               & (LAI_Height['Experiment'] == 'AshleyDene'), 'k'] = 0.66
```

```{python}
LAI_Height['Date'] = pd.to_datetime(LAI_Height['Clock.Today']).dt.strftime('%Y %b')
```

```{python}
# Check if the replace take effect
grid = sns.FacetGrid(LAI_Height, col ='Experiment', row = 'SowingDate', 
                      hue="SowingDate", palette="Set2",aspect=1.5, sharex=False)
grid.map(plt.scatter, 'Date', 'k')
grid.set_xticklabels(rotation=45)
grid.fig.tight_layout()
```

# Calculate $R/R_0$

```{python}
LAI_Height['LI_frac'] = 1 - np.exp( - LAI_Height['k'] * LAI_Height['LAImod'])
```

```{python}
# Check if any weired values. e.g. over 1 or below 0 
grid = sns.FacetGrid(LAI_Height, col ='Experiment',
                      hue="SowingDate", palette="Set1",aspect=2, sharex=False)
grid.map(plt.scatter, 'Date', 'LI_frac')
grid.set_xticklabels(rotation=45)
grid.fig.tight_layout()
```

```{python}

```

## Construct the index

```{python}
def print_full(x):
    pd.set_option('display.max_rows', len(x))
    print(x)
    pd.reset_option('display.max_rows')
```

```{python}
# Select only LI column
LI = LAI_Height.loc[:, ['Experiment', 'Clock.Today','SowingDate', 
                        'Rep', 'Plot', 
                        'LI_frac']]
# print_full(LI)
# remove the rows that have 0S - Likely to be wrong 0s
LI = LI[LI['LI_frac'] != 0.00]
LI
```

```{python}
LI[LI['SowingDate']=='SD5']
```

```{python}
LI = LI.pivot_table(index = 'Clock.Today', 
                    columns=['Experiment', 'SowingDate', 
                             'Rep', 'Plot'],
                    values = 'LI_frac')
LI
```

```{python}
# Check if the mean values capture all the harvest for SD5 
# SD5 has extra measurments in plot 15, 21,53,71
print_full(LI.filter(regex = 'SD5').groupby(axis = 1, level = ['Experiment','SowingDate']).mean())

```

```{python}
# Change the index to datetime tyep
LI.index = pd.to_datetime(LI.index)
# Rename the index name 
LI.index.name = 'Clock.Today'
# Normalise the datetime to midnight 
LI.index = LI.index.normalize()
```

```{python}
# Check indexs
LI.axes
```

## Calcuate the mean LI_frac

```{python}
LIGroupedMean = LI.groupby(axis=1, level=['Experiment', 'SowingDate']).mean()
```

```{python}
LIGroupedMean
```

```{python}
# Graph to check the data 

LIGroupedMean.loc[:,
                  [X for X in LIGroupedMean.columns if 'SD5' in X]].plot(figsize=(10, 6),style='o-')

```

```{python}
SDs = ['SD' + str(SD) for SD in range(1, 11)]
for i in SDs:
    LIGroupedMean.loc[:,
                  [X for X in LIGroupedMean.columns if i in X]].plot(figsize=(10, 6),style='o-')
```

# Met data to calculate thermal time 

```{python}
met_AD = met_AD.loc[:, ['year','day', 'maxt', 'mint','mean']]
met_AD['Experiment'] = 'AshleyDene'
met_I12 = met_I12.loc[(met_I12['year'] >= 2010)                       
                      & (met_I12['year'] < 2013), ['year','day', 'maxt', 'mint','mean']]
met_I12['Experiment'] = 'Iversen12'
```

```{python}
met = pd.concat([met_AD, met_I12], ignore_index=True)
```

```{python}
# Change 4 digits year to the first date of the year
met['year'] = [str(year) + '-01-01' for year in met['year']]
met['year'] = pd.to_datetime(met['year'])
# Change the day to a delta days and add back to the year 
met['Clock.Today'] = met['year'] + pd.to_timedelta(met['day'], unit='D')
```

```{python}
# Check if any weired values. 
grid = sns.FacetGrid(met, row ='Experiment',
                     aspect=2, sharex=False)
grid.map(plt.scatter, 'Clock.Today', 'mean')
grid.set_xticklabels(rotation=45)
grid.fig.tight_layout()
```

#### Note:   
1. The iversen 12 met has a long period of coverage.
   Expt period: **October 2010 to July 2012.**
   

```{python}
met = met[(met['Clock.Today'] > '2010-06-01')
          &(met['Clock.Today'] < '2012-08-01')]

```

```{python}
# Verify the filter 
# Check if any weired values. 
grid = sns.FacetGrid(met, row ='Experiment',
                     aspect=2, sharex=False)
grid.map(plt.scatter, 'Clock.Today', 'mean')
grid.set_xticklabels(rotation=45)
grid.fig.tight_layout()
```

```{python}
# indexing 
met.set_index('Clock.Today', inplace = True)
```

```{python}
met
```

```{python}
# Try 2 sites the same time 
ThermalTimeAccum = met.loc[:, 'mean'].cumsum()
ThermalTimeAccum.index = pd.to_datetime(ThermalTimeAccum.index)
```

```{python}

```

## Combine thermal time with cover data

```{python}
#Reindex coverdata frame to daily values
LIDaily = LI.reindex(ThermalTimeAccum.index)
LIDaily.loc[:, 'AccumTT'] = ThermalTimeAccum
# CoverDataDaily.loc[:,'AccumTT'] = ThermalTimeAccum
```

```{python}
print_full(LIDaily.filter(regex='SD5'))
```

## Interpolate daily values 

**Note**  
The for loop below complains _ValueError: fp and xp are not of the same length._  

This is probably because the LI is in a wide form 
But the thermal data is in a long form which includs two sites 


```{python}
# for p in LIDaily.columns:
#     Obs = LIDaily.loc[:,p].dropna()
#     LIDaily.loc[:,p] = np.interp(LIDaily.AccumTT, LIDaily.loc[Obs.index,'AccumTT'],Obs)
```

## Process sites individually   

Ashley Dene first

```{python}
LIAD = LI.filter(regex = 'Ashley')
LIDailyAD = LI.reindex(TTAccumAD.index)
LIDailyAD.loc[:, 'AccumTT'] = TTAccumAD

```

```{python}
LIDailyAD 
```

```{python}
TTAccumAD = met.loc[met['Experiment'] == 'AshleyDene', 'mean'].cumsum()
TTAccumAD.index = pd.to_datetime(TTAccumAD.index)
TTAccumAD.index = TTAccumAD.index.normalize()
```

```{python}
TTAccumAD
```

```{python}
LIDailyAD
```

```{python}
# for p in LIDailyAD.columns:
#     Obs = LIDailyAD.loc[:,p].dropna()
#     LIDailyAD.loc[:,p] = np.interp(LIDailyAD.AccumTT,
#                                    LIDailyAD.loc[Obs.index,'AccumTT'],Obs)
```

```{python}
LIDailyAD
```

```{python}
LIGroupedMeanAD = LIDailyAD.groupby(axis=1, level=['Experiment', 'SowingDate']).mean()
```

```{python}
LIGroupedMeanAD.columns
```

```{python}
# Graph to check the data 
LIGroupedMeanAD.loc[:,
                  [X for X in LIGroupedMeanAD.columns if X != (   'AccumTT',     '')]].plot(figsize=(10, 6),style='o-')
```

#### Notes

MAYBE the starting point need to be forced to be 0

## Iversen12 LI interpolate

```{python}
LII12 = LI.filter(regex = 'Ive')
LIDailyI12 = LIDaily.filter(regex = 'Ive')
TTAccumI12 = met.loc[met['Experiment'] == 'Iversen12', 'mean'].cumsum()
TTAccumI12.index = pd.to_datetime(TTAccumI12.index)
LIDailyI12 = LII12.reindex(TTAccumI12.index)  #Reindex coverdata frame to daily values
LIDailyI12.loc[:,'AccumTT'] = TTAccumI12
for p in LIDailyI12.columns:
    Obs = LIDailyI12.loc[:,p].dropna()
    LIDailyI12.loc[:,p] = np.interp(LIDailyI12.AccumTT,
                                   LIDailyI12.loc[Obs.index,'AccumTT'],Obs)
LIGroupedMeanI12 = LIDailyI12.groupby(axis=1, level=['Experiment', 'SowingDate']).mean()
```

```{python}
LIGroupedMeanI12.columns
```

```{python}
# Graph to check the data 
LIGroupedMeanI12.loc[:,
                  [X for X in LIGroupedMeanI12.columns if X != (   'AccumTT',     '')]].plot(figsize=(10, 6),style='o-')
```

# Force the starting point to be 0

```{python}
sowingdates = pd.read_sql('Select * from SowingDates',  con)
```

```{python}
sowingdates.AD = pd.to_datetime(sowingdates.AD)
sowingdates.I12 = pd.to_datetime(sowingdates.I12)

```

```{python}
# set index and rename columns 
sowingdates.set_index('SD', inplace=True)
sowingdates.columns = ['AshleyDene', 'Iversen12']
```

```{python}
sowingdates.loc
LIDailyAD.axes
```

```{python}
for col in LIDailyAD.columns:
    print(col)
```

```{python}
idx = pd.IndexSlice
LIDaily.loc[LIDaily.index == '2012-06-02', idx[:,'SD1']]
```

```{python}
for sd in sowingdates.index:
    date0 = sowingdates.at[sd, 'AshleyDene']
    idx = pd.IndexSlice
    df = LIDailyAD.loc[LIDailyAD.index == date0, idx[:,sd]]
    print(date0) 
    
    print(df)
        
#     print(sowingdates[sowingdates.index == sd])
#     print(LIDailyAD.loc[:, idx[:, sd]])

#         print(LIAD.loc[LIAD['Clock.Today'] == sd,col])
```

```{python}
LIDailyAD.loc[LIDailyAD.index == '2010-11-12', idx[:, 'SD1']]
```

```{python}
LIDailyAD.filter(regex = 'SD5')

```

```{python}
LIDaily.index.unique()
```

#### Note   
There are still more than 4 plots for each sowing dates   
Due to seed line and harvest.no.  
The harvest.no **post** did not contribute to LAI. so should taken out.   
The Thermaltime df has duplicated the index.

```{python}
sowingdates.loc[sowingdates.index == 'SD1','AshleyDene']
```
